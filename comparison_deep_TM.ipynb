{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorboard_projector_plugin.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96294db7543d4902b2bf5c805501a9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b8519b43f4df422a8cea298ec19a3c76",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ceae104f42ce44cf9068b3da073ab7fd",
              "IPY_MODEL_a52f0ce32345450689492bbad96ed1c5"
            ]
          }
        },
        "b8519b43f4df422a8cea298ec19a3c76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ceae104f42ce44cf9068b3da073ab7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b162f42203a42aba12459ef223beee8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 403747457,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 403747457,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1f620a3c6534143879c6cf420f25797"
          }
        },
        "a52f0ce32345450689492bbad96ed1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce66992c4e6749a2b1cd0c4b47751c49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 404M/404M [00:27&lt;00:00, 14.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de2189f21a6a46c48f679129a1df8795"
          }
        },
        "2b162f42203a42aba12459ef223beee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1f620a3c6534143879c6cf420f25797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce66992c4e6749a2b1cd0c4b47751c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de2189f21a6a46c48f679129a1df8795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashjorss/topic_modelling/blob/main/comparison_deep_TM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JXr1g7obLM4"
      },
      "source": [
        "#different versio of numpy required for top2vec\n",
        "!pip uninstall numpy\n",
        "!pip install numpy==1.19.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaOLePJuGjO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebdd75ec-0794-478a-ec7c-81b71f477f4f"
      },
      "source": [
        "#install the packages\n",
        "# !pip install sentence-transformers\n",
        "# !pip install nltk\n",
        "# !pip install torch\n",
        "# !pip install tensorflow\n",
        "# !pip install tensorboard\n",
        "# !pip install top2vec\n",
        "# !pip install top2vec[sentence_encoders]\n",
        "# !pip install top2vec[sentence_transformers]\n",
        "# !pip install torch sentence_transformers\n",
        "# !pip install top2vec[indexing]\n",
        "!pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.95)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.9.1+cu101)\n",
            "Requirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.20.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_L0sV00ZLYi"
      },
      "source": [
        "#import required packages\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olyW_M3saRRW"
      },
      "source": [
        "!git clone https://github.com/akashjorss/sentence_bert\n",
        "!unzip sentence_bert/sentences.zip\n",
        "import pickle\n",
        "with open('sentences.bin', 'rb') as f:\n",
        "  sentences = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0on38X_aUTh"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# import tensorflow_datasets as tfds\n",
        "# from tensorboard.plugins import projector\n",
        "# #load tensorboards with magics\n",
        "# %tensorflow_version 2.x\n",
        "# %load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNQdC9K5aZ8D"
      },
      "source": [
        "documents = random.choices(sentences,k = 100000)\n",
        "documents = [d.lower() for d in documents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfSU1I3u-K8f",
        "outputId": "c6b59dba-d792-48d5-951b-a319ecdaacaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "96294db7543d4902b2bf5c805501a9c2",
            "b8519b43f4df422a8cea298ec19a3c76",
            "ceae104f42ce44cf9068b3da073ab7fd",
            "a52f0ce32345450689492bbad96ed1c5",
            "2b162f42203a42aba12459ef223beee8",
            "c1f620a3c6534143879c6cf420f25797",
            "ce66992c4e6749a2b1cd0c4b47751c49",
            "de2189f21a6a46c48f679129a1df8795"
          ]
        }
      },
      "source": [
        "sbert_model = SentenceTransformer('stsb-mpnet-base-v2')\n",
        "torch.save(sbert_model, \"./stsb-mpnet-base-v2.pt\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96294db7543d4902b2bf5c805501a9c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=403747457.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlX31kBHMAnQ",
        "outputId": "39476bc6-6cd8-4612-a70e-78dcbacb1ad5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  sentence_bert  sentences.bin  stsb-mpnet-base-v2.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ3yN_mdZY9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a789ae9-3041-41e6-d8be-4c40028ef0c0"
      },
      "source": [
        "from top2vec import Top2Vec\n",
        "# use = Top2Vec(documents, embedding_model='universal-sentence-encoder', workers=4, document_ids=list(range(0,len(documents))))\n",
        "# sbert = Top2Vec(documents, embedding_model_path='./stsb-mpnet-base-v2.pt', workers=4, document_ids=list(range(0,len(documents)))) #download sentence sbert\n",
        "# doc2vec = Top2Vec(documents, embedding_model='doc2vec', workers=4, document_ids=list(range(0,len(documents))), speed=\"deep-learn\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-02 14:46:20,598 - top2vec - INFO - Pre-processing documents for training\n",
            "INFO:top2vec:Pre-processing documents for training\n",
            "2021-06-02 14:46:24,564 - top2vec - INFO - Creating joint document/word embedding\n",
            "INFO:top2vec:Creating joint document/word embedding\n",
            "2021-06-02 14:52:50,523 - top2vec - INFO - Creating lower dimension embedding of documents\n",
            "INFO:top2vec:Creating lower dimension embedding of documents\n",
            "2021-06-02 14:54:47,224 - top2vec - INFO - Finding dense areas of documents\n",
            "INFO:top2vec:Finding dense areas of documents\n",
            "2021-06-02 14:54:53,926 - top2vec - INFO - Finding topics\n",
            "INFO:top2vec:Finding topics\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aOZAQwvfO8Q",
        "outputId": "7448f4a5-3e17-48ec-e8a0-032b04c3bd52"
      },
      "source": [
        "print(\"Total num of topics in USE:\", use.get_num_topics())\n",
        "print(\"Total num of topics in doc2vec:\", doc2vec.get_num_topics())\n",
        "print(\"Total num of topics in sentence-bert:\", sbert.get_num_topics())"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total num of topics in USE: 430\n",
            "Total num of topics in doc2vec: 1069\n",
            "Total num of topics in sentence-bert: 1329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNSs7r_UETCH",
        "outputId": "4206844e-6447-42a9-cbc1-e8a52b9c27a7"
      },
      "source": [
        "def calc_IG(words, docs):\n",
        "  \"\"\"calculate information gain for a topic in topic model containing words and documents\n",
        "  args:\n",
        "    words (list): list of top words in the topic. \n",
        "    docs (list): list of docs in the topic\n",
        "  returns:\n",
        "    ig (float): information gain of this topic with respect to total independence b/w words and docs\"\"\"\n",
        "  #sanity check\n",
        "  assert(len(words)!=0)\n",
        "  assert(len(docs)!=0)\n",
        "  words = list(set(words)) #drop the redundant words\n",
        "  #convert words to lower case\n",
        "  words = [word.lower() for word in words]\n",
        "  #tokenize the docs using nltk punkt\n",
        "  tokenized_docs = [word_tokenize(doc.lower()) for doc in docs]\n",
        "  #create inverted index between words and docs\n",
        "  inverted_index = np.zeros((len(words),len(docs)))\n",
        "  for i in range(len(words)):\n",
        "    for j in range(len(docs)):\n",
        "      inverted_index[i][j] = tokenized_docs[j].count(words[i])\n",
        "  # print(words)\n",
        "  # print(inverted_index)\n",
        "  ig = 0.0\n",
        "  P_d = 1/len(docs)\n",
        "  P_w = 1/len(words)\n",
        "  for i in range(len(words)):\n",
        "    for j in range(len(docs)):\n",
        "      if np.sum(inverted_index[i]) != 0:\n",
        "        P_dw = inverted_index[i][j]/np.sum(inverted_index[i]) #total number of documents in which w occurs\n",
        "        if P_dw != 0:\n",
        "          ig += P_dw*P_w*np.log2(P_dw/P_d)\n",
        "  \n",
        "  return ig     \n",
        "\n",
        "#test\n",
        "doc1 = \"The big sharks of Belgium drink beer.\"\n",
        "doc2 = \"Belgium has great beer. They drink beer all the time.\"\n",
        "doc3 = \"They drink a lot of beer in Belgium\"\n",
        "doc4 = \"cha cha\"\n",
        "words = [\"so\", \"what\"]\n",
        "docs = [doc1, doc2, doc3, doc4]\n",
        "calc_IG(words, docs)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORwGQbt5hEF_"
      },
      "source": [
        "#create a dictionary with key as topic_id and values as list of top 10 words. \n",
        "def calculate_total_information_gain(model, n_topics, k_words = 10):\n",
        "  \"\"\"This function calculates the total information gain of the model.\n",
        "  args:\n",
        "    model (Top2Vec): Top2Vec model used in encoding word and document vectors\n",
        "    n_topics(int): Number of topics to reduce the model to\n",
        "    k_words(int): To consider top k words (by distance) for each topic while calculating IG\n",
        "  returns:\n",
        "    total_IG (float): sum of information gain of all the clusters\"\"\" \n",
        "  \n",
        "  #reduce the number of topics in model using hierarchical clustering\n",
        "  print(\"Reducing number of topics to\", n_topics, \"...\")\n",
        "  model.hierarchical_topic_reduction(n_topics)\n",
        "\n",
        "  #get topic words and ids\n",
        "  topic_words, similarity_scores, topic_ids = model.get_topics(reduced=True)\n",
        "  \n",
        "  #Get the keywords of each topic\n",
        "  #create a dictionary with key as topic_id and values as list of document ids\n",
        "  print(\"Building topic index for keywords...\")\n",
        "  topic_words_dict = {}\n",
        "  for i in range(len(topic_words)):\n",
        "    topic_words_dict[i] = topic_words[i][:k_words] #top k words\n",
        "\n",
        "  #Get the topic number of each document\n",
        "  #create a dictionary with key as topic_id and values as list of document ids\n",
        "  print(\"Building topic index for documents...\")\n",
        "  topic_docs_dict = {}\n",
        "  for i in range(len(topic_ids)): \n",
        "    topic_docs_dict[i] = []\n",
        "\n",
        "  for i in range(len(documents)):\n",
        "    topic_id, _, _, _ = model.get_documents_topics([i], reduced=True)\n",
        "    topic_docs_dict[topic_id[0]].append(i)\n",
        "\n",
        "  \n",
        "  #get documents and keywords of each cluster and calculate the information gain\n",
        "  print(\"Calculating information gain...\")\n",
        "  total_ig = 0\n",
        "  for key in tqdm(topic_words_dict):\n",
        "    words = topic_words_dict[key]\n",
        "    doc_ids = topic_docs_dict[key]\n",
        "    docs = np.take(documents, doc_ids)\n",
        "    topic_ig = calc_IG(words, docs)\n",
        "    print(\"\\nInformation gain for topic\", key, \": \", topic_ig)\n",
        "    total_ig += topic_ig\n",
        "\n",
        "  return total_ig"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_hBfTBSvi_4",
        "outputId": "d302e0ba-f98d-4c6f-eccc-4fb7ae0e9b17"
      },
      "source": [
        "#plot total information gain\n",
        "x = []\n",
        "y_use = []\n",
        "y_sbert = []\n",
        "y_doc2vec = []\n",
        "for i in range(1,302,100):\n",
        "  if i == 0:\n",
        "    n_topics = 1\n",
        "  else:\n",
        "    n_topics = i\n",
        "  \n",
        "  x.append(n_topics)\n",
        "  ig_use = calculate_total_information_gain(use, n_topics, k_words=10)\n",
        "  ig_sbert = calculate_total_information_gain(sbert, n_topics, k_words=10)\n",
        "  ig_doc2vec = calculate_total_information_gain(doc2vec, n_topics, k_words=10)\n",
        "  y_use.append(ig_use)\n",
        "  y_sbert.append(ig_sbert)\n",
        "  y_doc2vec.append(ig_doc2vec)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x,y_use, label=\"use\")\n",
        "plt.plot(x,y_sbert, label=\"sbert\")\n",
        "plt.plot(x, y_doc2vec, label=\"doc2vec\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reducing number of topics to 1 ...\n",
            "Building topic index for keywords...\n",
            "Building topic index for documents...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Calculating information gain...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:19<00:00, 79.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Information gain for topic 0 :  7.575572203030304\n",
            "Reducing number of topics to 1 ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKsHndpWepGN"
      },
      "source": [
        "#testing word similarity (to be used in zero shot classification)\n",
        "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"swimming\"], num_topics=3, reduced=False) #swimming, cleanliness #keywords_neg=stop,\n",
        "for topic in topic_nums:\n",
        "    model.generate_topic_wordcloud(topic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyzIUIlM93EE"
      },
      "source": [
        "\"\"\"Some thoughts:\n",
        "Inside a cluster: documents should be similar to each other. Perhaps coherence measures that. \n",
        "\n",
        "Now, for Mutual Information: It tells us, if given some words, does it tell us anything about the documents?\n",
        "We kind of changed it slightly because now we are taking top 20 words. We are not even taking the frequency\n",
        "of these words in fact. Just the set of these. \n",
        "So what is the question we are asking within a topic? What kind of behavior we want to model?\n",
        "Given a list of top n words, we want these words to describe the topic. \n",
        "In terms of MI, it will be 0 if \n",
        "1)words are not related to the topic, \n",
        "2)words are too common that they occur virtually in all the docs, e.g., stop words. \n",
        "But what about the words that are representative of the topics and occur in most of the docs in a topic?\n",
        "They will count less towards MI. e.g. Belgium and Beer in the above example. I guess this is one caveat of this. \n",
        "But overall, I think IG should be higher if topic words are represntative.\n",
        "Also, perhaps there is a way to calculate sentence similarity within topics. A metric of topic coherence based on deep learning.\n",
        "Comparing words with each after doing TF-IDF, removing stop words, etc.  \n",
        "\n",
        "Also, some text engineering is required to improve the results. \n",
        "1. Named entity recognition. \n",
        "2. Sentiment word recognition. \n",
        "3. Removing the clusters, whose representative words are most of the above two. (e.g. > 50%). Then,\n",
        "  merge those documents with the nearest clusters. \n",
        "\n",
        "Some thoughts about the coherence score:\n",
        "The traditional coherence score, while good for obtaining the overall performance of the model doesn't \n",
        "take into account the semantic similarity of different words and docs. To truly observe the power of\n",
        "deep learning models we need semantic similarity score which can compare two documents based on their \n",
        "representational similarity, and also take context into account. \n",
        "Within a topic, pairwise comparisons can take place. And the sum of those similarity scores is the coherence of that topic. \n",
        "The sum of coherence of all the topics is the total coherence of the model. \n",
        "1. The simplest way to do it is just to take a vector distance for pairwise comparison. Simply substract the vectors from each other\n",
        "and take their absolute value. \n",
        "2. The more sophisticated way would be to remove stop words from two sentences and and somehow do word by word comparison. But \n",
        "sentence-BERT is trained on the semantic similarity task, so it is exactly that task. It should be good to go to measure pairwise \n",
        "similarity. But I should read the sentence-BERT paper. \n",
        "3. The above two metrics may not work with LDA. So, maybe we will have to retort to the traditional coherence score as well.  \n",
        "\n",
        "Comments about cluster reduction:\n",
        "Is hierarchical clustering best way to reduce the number of clusters? What are the alternatives?\n",
        "\"\"\" \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DD1gH0CEZ0d"
      },
      "source": [
        "Calculate coherence score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1M_QsJbFYYq"
      },
      "source": [
        "def cos_similarity(vector1, vector2):\n",
        "  \"\"\"This functions finds the similarity between doc1 and doc2 using cosine similarity. \n",
        "  args:\n",
        "    vector1(list-like): document embedding 1\n",
        "    vector2(list-like): document embedding 2\n",
        "  returns:\n",
        "    cos_sim(float): cosine similarity score between vector1 and vector2\"\"\"\n",
        "  cos_sim = np.dot(vector1, vector2)/(np.linalg.norm(vector1)*np.linalg.norm(vector2))\n",
        "  return cos_sim\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv6YBP8dIhIS"
      },
      "source": [
        "def coherence(doc_vectors):\n",
        "  \"\"\"This function calculates the topic coherence by taking pairwise cosine similarity\n",
        "  args:\n",
        "    doc_vectors(list-like): list of document vectors(512 or 768 dim)\n",
        "  returns:\n",
        "    coherence_score(float)\"\"\"\n",
        "  num_docs = len(doc_vectors)\n",
        "  coherence_score = 0\n",
        "  similarity_matrix = np.zeros((num_docs, num_docs))\n",
        "  for i in range(num_docs):\n",
        "    for j in range(num_docs):\n",
        "      if i!=j: #the similarity of doc to itself is 1 but we don't count it, so in this matrix it is 0\n",
        "        coherence_score += cos_similarity(doc_vectors[i], doc_vectors[j])\n",
        "\n",
        "  return coherence_score"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZQEtvBcLDub"
      },
      "source": [
        "def calculate_total_coherence(model, docs):\n",
        "  \"\"\"calculates total coherence for a model. Setences should encoded by the same model to calculate similarity or by some\n",
        "  external model more suitable for pairwise comparison to make sense. If I encode with sbert, then it will be biased towards sbert\"\"\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZvWcAdU8vLd"
      },
      "source": [
        "Visualization using tensorboard projector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsyVBhzyPd_U"
      },
      "source": [
        "#get document vectors and plot using umap and tensorboard\n",
        "#dim reduction using umap\n",
        "import umap\n",
        "umap_embeddings = umap.UMAP(n_neighbors=15,\n",
        "                            n_components=3, \n",
        "                            metric='cosine').fit_transform(model.document_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sev-FR1-P2o7"
      },
      "source": [
        "#visualize high dim data in embedding projector\n",
        "# Set up a logs directory, so Tensorboard knows where to look for files\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "log_dir='./logs/'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "# Save the weights we want to analyse as a variable. \n",
        "umap_weights = tf.Variable(random.choices(umap_embeddings, k=10000))\n",
        "# Create a checkpoint from embedding, the filename and key are\n",
        "# name of the tensor.\n",
        "checkpoint = tf.train.Checkpoint(embedding=umap_weights)\n",
        "checkpoint.save(os.path.join(log_dir, \"umap_embedding.ckpt\"))\n",
        "\n",
        "# Set up config\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
        "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "# embedding.metadata_path = 'metadata.tsv'\n",
        "projector.visualize_embeddings(log_dir, config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bg-_0DWQEto"
      },
      "source": [
        "%tensorboard --logdir ./logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOxfH6KzYvdb"
      },
      "source": [
        "#visualize word embeddings: get rid of stopwords, sentiment words, and take more sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuKztLMlh8jR"
      },
      "source": [
        "#function to process sentence to remove stopwords and sentiment words\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "def process_sentence(s):\n",
        "  s = s.lower()\n",
        "\n",
        "  stop = stopwords.words('english')\n",
        "  sentiment_tags = ['ADJ', 'ADV', 'RB', 'VBZ']\n",
        "\n",
        "\n",
        "  words = word_tokenize(s)\n",
        "  #remove stop words\n",
        "  words = [w for w in words if w not in stop]\n",
        "  #remove sentiment words\n",
        "  pos_tags = nltk.pos_tag(words)\n",
        "  words = [t[0] for t in pos_tags if t[1] not in sentiment_tags]\n",
        "  s = \" \".join(words)\n",
        "  return s"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}