{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('topic_modelling': conda)"
  },
  "interpreter": {
   "hash": "33ea4571294b160a8c9ba59d2d1217d533cade9e0aa979f130bb0787997e3281"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is to get some insights about the clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#transformer imports\n",
    "from top2vec import Top2Vec\n",
    "\n",
    "#miscellaneous\n",
    "import fasttext\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "sbert = Top2Vec.load(\"models/sbert_top2vec_without_preprocessing.bin\")\n",
    "print(\"Total num of topics in sbert:\", sbert.get_num_topics())\n",
    "#Number of words in a topic. \n",
    "#Also, how is the importance of word calculated? Frequency? How about duplicated words. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_without_preprocessing = Top2Vec.load(\"models/doc2vec_top2vec_without_preprocessing.bin\")\n",
    "doc2vec_without_preprocessing.hierarchical_topic_reduction(100)\n",
    "doc2vec = Top2Vec.load(\"models/doc2vec_top2vec.bin\")\n",
    "doc2vec.hierarchical_topic_reduction(100)\n",
    "sbert_without_preprocessing = Top2Vec.load(\"models/sbert_top2vec_without_preprocessing.bin\")\n",
    "sbert_without_preprocessing.hierarchical_topic_reduction(100)\n",
    "sbert = Top2Vec.load(\"models/sbert_top2vec.bin\")\n",
    "sbert.hierarchical_topic_reduction(100)\n",
    "use_without_preprocessing = Top2Vec.load(\"models/use_top2vec_without_preprocessing.bin\")\n",
    "use_without_preprocessing.hierarchical_topic_reduction(100)\n",
    "use = Top2Vec.load(\"models/use_top2vec.bin\")\n",
    "use.hierarchical_topic_reduction(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get topic sizes\n",
    "topic_sizes, topic_nums = use.get_topic_sizes(reduced=False)\n",
    "plt.hist(topic_sizes, bins = 100, alpha=0.5)\n",
    "plt.xlim(0,1000)\n",
    "plt.xlabel('Number of documents')\n",
    "plt.title(\"Distribution of Number of docs across different topics(USE)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_scores, doc_ids = doc2vec.search_documents_by_keywords(['dirty', 'covid', 'clean'], 5)\n",
    "# with open('booking_sentences_processed.txt', 'r') as f:\n",
    "#     documents = f.readlines()\n",
    "# for i in doc_ids:\n",
    "#     print(documents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing word similarity (to be used in zero shot classification)\n",
    "keywords = ['hotel']\n",
    "topic_words, word_scores, topic_scores, topic_nums = use.search_topics(keywords=keywords, num_topics=3, reduced=False)\n",
    "for topic in topic_nums:\n",
    "    use.generate_topic_wordcloud(topic, background_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words, similarity_scores, topic_ids = sbert.get_topics(reduced=False)\n",
    "for topic_num in topic_ids[:10]:\n",
    "  sbert.generate_topic_wordcloud(topic_num, background_color='white', reduced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "unable to read local cache '/home/akash/gensim-data/information.json' during fallback, connect to the Internet and retry",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/topic_modelling/lib/python3.8/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/akash/gensim-data/information.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-165fd4171fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'newsgroups.dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'newsgroups.dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/topic_modelling/lib/python3.8/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \"\"\"\n\u001b[1;32m    488\u001b[0m     \u001b[0m_create_base_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incorrect model/corpus name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/topic_modelling/lib/python3.8/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_get_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m     \u001b[0minformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m     \u001b[0mcorpora\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'corpora'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/topic_modelling/lib/python3.8/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36minfo\u001b[0;34m(name, show_only_latest, name_only)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0minformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/topic_modelling/lib/python3.8/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0;34m'unable to read local cache %r during fallback, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;34m'connect to the Internet and retry'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcache_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unable to read local cache '/home/akash/gensim-data/information.json' during fallback, connect to the Internet and retry"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary.load('newsgroups.dict')\n",
    "corpus = gensim.corpora.MmCorpus('newsgroups.mm')\n",
    "# lda = gensim.models.ldamodel.LdaModel.load('newsgroups_50.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}